{"cells":[{"metadata":{"_uuid":"1de8be1f-9195-4dd7-9285-6499907eaff7","_cell_guid":"817d76b6-6802-4537-a628-10d37f46d5f9","trusted":true,"id":"j8t-7WQ4c8dm","outputId":"c4b63fb9-710b-465a-d5d7-c652ba106355"},"cell_type":"code","source":"!pip install tokenizer\n!pip install transformers","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"84f6d4dc-eb66-4ffb-ab2f-219ed56024e3","_cell_guid":"8f6c0d06-50af-4089-9fa6-5b52c4242254","trusted":true,"id":"7-tRzmWtbrWW"},"cell_type":"code","source":"import pandas as pd, numpy as np\nimport tensorflow as tf \nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import *\nimport tokenizers","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"60603245-0137-4121-af18-6401ef1232e5","_cell_guid":"61774d3a-62fc-4033-acd8-1a1675b5f9e6","trusted":true,"id":"ZsGx6lqIjCB4"},"cell_type":"code","source":"import io\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"02e9b098-b5db-46ab-ab92-2d25488c0052","_cell_guid":"de4ed5ed-9c99-463d-ad15-6d9b6051f082","trusted":true,"id":"90pfFc9ph28S","outputId":"59bd5dca-b8fd-494a-a52d-636cb12fad02"},"cell_type":"code","source":"MAX_LEN = 96\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab_file='../input/tf-roberta/vocab-roberta-base.json', \n    merges_file='../input/tf-roberta/merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True\n)\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\ntrain.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"27f6eef1-6eca-4dfc-8592-e1476f67e4d7","_cell_guid":"2c589aec-e83e-4027-aecb-6b2821f03428","trusted":true,"id":"qApXd5fkjOcj"},"cell_type":"code","source":"# Converting training Data into arrays:\n\nct = train.shape[0]\ninput_ids = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\nstart_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\nend_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(train.shape[0]):\n    \n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n    text2 = \" \".join(train.loc[k,'selected_text'].split())\n    idx = text1.find(text2)\n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)]=1\n    if text1[idx-1]==' ': chars[idx-1] = 1 \n    enc = tokenizer.encode(text1) \n        \n    # ID_OFFSETS\n    offsets = []; idx=0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx,idx+len(w)))\n        idx += len(w)\n    \n    # START END TOKENS\n    toks = []\n    for i,(a,b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm>0: toks.append(i) \n        \n    s_tok = sentiment_id[train.loc[k,'sentiment']]\n    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask[k,:len(enc.ids)+5] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+1] = 1\n        end_tokens[k,toks[-1]+1] = 1","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"184c7662-48b5-46c2-82cf-f7622afb301f","_cell_guid":"82302093-023e-4318-acf5-6df7510b48ae","trusted":true,"id":"yPAmN-nClTFy"},"cell_type":"code","source":"# Test data:\n\ntest = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n\nct = test.shape[0]\ninput_ids_t = np.ones((ct, MAX_LEN), dtype='int32')\nattention_mask_t = np.zeros((ct, MAX_LEN), dtype='int32')\ntoken_type_ids_t = np.zeros((ct, MAX_LEN), dtype='int32')\n\nfor k in range(test.shape[0]):\n\n  text1 = ' '+' '.join(test.loc[k, 'text'].split())\n  enc = tokenizer.encode(text1)\n  s_tok = sentiment_id[test.loc[k, 'sentiment']]\n  input_ids_t[k, : len(enc.ids) + 5] = [0] + enc.ids + [2, 2] + [s_tok] + [2]\n  attention_mask_t[k, : len(enc.ids) + 5] = 1","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"0b391458-5c62-4bda-b5b7-db6775916448","_cell_guid":"eda142a4-6016-42ac-82f8-be8e2db46b02","trusted":true,"id":"3SuZvMkJk_A6"},"cell_type":"markdown","source":"## **Building the Model**"},{"metadata":{"_uuid":"ac82bd9e-a314-4245-9af3-f67ffb7c998a","_cell_guid":"aed1116c-3afa-4c65-8849-ab840af79289","trusted":true,"id":"BssGQqB0kc6p"},"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n\n    config = RobertaConfig.from_pretrained('../input/tf-roberta/config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained('../input/tf-roberta/pretrained-roberta-base.h5',config=config)\n    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n    \n    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n\n    return model","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"02160abb-6e10-4894-a756-3a49102fffe4","_cell_guid":"2d1634a0-0311-48e9-b958-41bc6080c9c7","trusted":true,"id":"Q8suKFDLt4i0"},"cell_type":"code","source":"# Metric:\n\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a)==0) & (len(b)==0): return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a4532c36-d0c6-4d33-abc6-a388388ae8c7","_cell_guid":"dcdc2378-f776-4ced-9670-4b303da23d10","trusted":true,"id":"GFDaPxf5eQHf","outputId":"2ed19119-6216-46a8-cc0e-6e2f2a618df1"},"cell_type":"code","source":"jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\noof_start = np.zeros((input_ids.shape[0],MAX_LEN))\noof_end = np.zeros((input_ids.shape[0],MAX_LEN))\npreds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\npreds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n\nskf = StratifiedKFold(n_splits=5,shuffle=True,random_state=777)\nfor fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n\n    print('#'*25)\n    print('### FOLD %i'%(fold+1))\n    print('#'*25)\n    \n    K.clear_session()\n    model = build_model()\n        \n    sv = tf.keras.callbacks.ModelCheckpoint(\n        '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='auto', save_freq='epoch')\n        \n    model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n        epochs=3, batch_size=32, verbose=DISPLAY, callbacks=[sv],\n        validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n        [start_tokens[idxV,], end_tokens[idxV,]]))\n    \n    print('Loading model...')\n    model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n    \n    print('Predicting OOF...')\n    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n    \n    print('Predicting Test...')\n    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n    preds_start += preds[0]/skf.n_splits\n    preds_end += preds[1]/skf.n_splits\n    \n  # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k,])\n        b = np.argmax(oof_end[k,])\n        if a>b: \n            st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n        else:\n            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-1:b])\n        all.append(jaccard(st,train.loc[k,'selected_text']))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n    print()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a55839b7-b988-4192-9511-da22be4da707","_cell_guid":"45e1a2cc-eccd-4cf2-a4e2-74829ccca0d8","trusted":true,"id":"vMmcb3_IekOj","outputId":"2c2666ea-8bac-41ee-a4cb-4fcaad7e07f6"},"cell_type":"code","source":"# Jaccard:\n\nprint('Jaccard Pontuation: ', format(np.mean(jac)))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"13badf61-4809-4f68-85c2-61576a625671","_cell_guid":"451fb253-8a56-4d6f-923b-5afb539c0119","trusted":true,"id":"Q-Ndr_4PNAhz"},"cell_type":"markdown","source":"## **Submittion**"},{"metadata":{"_uuid":"95f3c563-83e6-4932-9055-3ba1475d4141","_cell_guid":"4335ad66-32ba-4d38-852b-086177b40171","trusted":true,"id":"dI9SXjrFM324"},"cell_type":"code","source":"all = []\nfor k in range(input_ids_t.shape[0]):\n    a = np.argmax(preds_start[k,])\n    b = np.argmax(preds_end[k,])\n    if a>b: \n        st = test.loc[k,'text']\n    else:\n        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n        enc = tokenizer.encode(text1)\n        st = tokenizer.decode(enc.ids[a-1:b])\n    all.append(st)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"62df01f5-5fd6-4c26-8dcb-247589d0a2c7","_cell_guid":"8a27d1ea-7aa9-49c3-a11a-9da644b9f847","trusted":true,"id":"xN8C0DOHNCrv"},"cell_type":"code","source":"test['selected_text'] = all\ntest[['textID','selected_text']].to_csv('submission.csv',index=False)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9f29dabd-30d3-475b-8577-7f9b7d7e6063","_cell_guid":"1c2897f2-c010-452f-98c8-1ab8769c3acc","trusted":true,"id":"c0JvlsRUNHa-","outputId":"e1cf8d84-c444-4ccc-a029-2cd155efe9b6"},"cell_type":"code","source":"test","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c70d4e16-1cf8-4a87-900f-372a7d0e5bd1","_cell_guid":"6503528e-79db-4b55-aa60-3659ae44a9fb","trusted":true,"id":"AvS8LrjUNIkw"},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}